# Enhanced GPT Ranker Configuration
# Optimized for HIGH-SCORE UNFILED qui tam cases

# Input/Output paths
input = "data/processed/combined_qui_tam_data.csv"
output = "data/results/qui_tam_ranked.csv"
json-output = "data/results/qui_tam_ranked.jsonl"

# Use enhanced prompt that produces higher scores for unfiled cases
prompt-file = "prompts/enhanced_qui_tam_prompt.txt"

# CRITICAL: Disable chunking for single-file output
chunk-size = 0

# Model configuration  
endpoint = "http://127.0.0.1:1234/v1"
model = "openai/gpt-oss-120b"
temperature = 0.0
timeout = 600.0

# Processing options
resume = false
# Remove max-rows or increase for full processing
# max-rows = 10

# Optional: Energy tracking
# power-watts = 350.0
# electric-rate = 0.12
